# -*- coding: utf-8 -*-
"""model_implementation_riskscores.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AjNfsKBYjyylHkOUQYBz3Q7kjZW3k2_4
"""

import numpy as np
import pandas as pd

df=pd.read_csv('/content/drive/MyDrive/Copy of geo+risk.csv')

df

for col in df.columns:
  print(col)

risks=['Mental_Health_RiskScore',
'Discrimination_RiskScore',
'Housing_RiskScore',
'SelfCare_RiskScore',
'FamilyConflicts_RiskScore',
'Transportation_RiskScore',
'Financial_RiskScore',
'Educational_RiskScore',

'Environmental_RiskScore',
'Technical_RiskScore']

y=df[risks]

X=df[['Latitude',
'Longitude']]

X

y

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

"""# Neural Networks"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the input data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the architecture of the neural network
model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(512, activation='relu'),
    Dense(1024, activation='relu'),
    Dense(y_train.shape[1])  # Output layer with the same number of features as y
])

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model on the testing set
y_pred = model.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)

print("Mean Squared Error on Test Set:", mse)

import matplotlib.pyplot as plt
# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

y_test

y_pred

# Convert the predictions to a DataFrame
y_pred_df = pd.DataFrame(y_pred, columns=y.columns)

# Convert y_test to a DataFrame
y_test_df = pd.DataFrame(y_test.values, columns=y.columns)

# Concatenate actual and predicted values
result_df = pd.concat([y_test_df, y_pred_df], axis=1)
result_df.columns = ['Actual ' + col for col in y_test_df.columns] + ['Predicted ' + col for col in y_pred_df.columns]

# Print the result DataFrame
for col in y_test_df.columns:

    print(result_df[['Actual '+col,'Predicted '+col]])

"""# Graph Neural Networks"""

!pip install torch_geometric

import torch
import torch.nn as nn
import torch.optim as optim
from torch_geometric.data import Data
from torch_geometric.nn import MessagePassing
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Step 1: Preprocessing
#data = pd.read_csv('your_data.csv')  # Replace 'your_data.csv' with your data file path


# Train-test split
import torch
from torch.nn import Module, Linear
import torch.nn.functional as F
import torch.optim as optim
from torch_geometric.nn import MessagePassing
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# Step 1: Data Preprocessing
# Assuming you have X and y defined

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Define GNN Model
class GNNModel(MessagePassing):
    def __init__(self):
        super(GNNModel, self).__init__(aggr='mean')
        self.lin1 = Linear(2, 128)  # Input layer (latitude, longitude) to 64 hidden units
        self.lin2 = Linear(128, y.shape[1])  # 64 hidden units to output dimension

    def forward(self, x, edge_index):
        x = self.lin1(x)
        x = self.lin2(x)
        return x

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GNNModel().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.MSELoss()

# Step 3: Training
x_train_tensor = torch.tensor(X_train.values, dtype=torch.float).to(device)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).to(device)
x_test_tensor = torch.tensor(X_test.values, dtype=torch.float).to(device)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float).to(device)
edge_index = torch.tensor([[0, 1]], dtype=torch.long).to(device)  # Assuming only one edge between latitude and longitude

def train_model(model, optimizer, criterion, x_train, y_train, x_test, y_test, edge_index, epochs=100):
    model.train()
    train_losses = []
    test_losses = []
    for epoch in range(epochs):
        optimizer.zero_grad()
        out_train = model(x_train, edge_index)
        loss_train = criterion(out_train, y_train)
        loss_train.backward()
        optimizer.step()

        out_test = model(x_test, edge_index)
        loss_test = criterion(out_test, y_test)

        train_losses.append(loss_train.item())
        test_losses.append(loss_test.item())

        if epoch % 10 == 0:
            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {loss_train.item()}, Test Loss: {loss_test.item()}')

    return train_losses, test_losses

train_losses, test_losses = train_model(model, optimizer, criterion, x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, edge_index)

# Step 4: Plotting
plt.figure(figsize=(10, 5))
epochs = range(1, len(train_losses) + 1)
plt.plot(epochs, train_losses, label='Train Loss')
plt.plot(epochs, test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Mean Squared Error')
plt.title('Train and Test Losses Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

import torch
from torch.nn import Module, Linear
import torch.nn.functional as F
import torch.optim as optim
from torch_geometric.nn import MessagePassing
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# Step 1: Data Preprocessing
# Assuming you have X and y defined

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Define GNN Model
class GNNModel(MessagePassing):
    def __init__(self):
        super(GNNModel, self).__init__(aggr='mean')
        self.lin1 = Linear(2, 64)  # Input layer (latitude, longitude) to 64 hidden units
        self.lin2 = Linear(64, y.shape[1])  # 64 hidden units to output dimension

    def forward(self, x, edge_index):
        x = self.lin1(x)
        x = self.lin2(x)
        return x

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GNNModel().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.MSELoss()

# Convert data to tensors and move to appropriate device
x_train_tensor = torch.tensor(X_train.values, dtype=torch.float).to(device)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).to(device)
x_test_tensor = torch.tensor(X_test.values, dtype=torch.float).to(device)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float).to(device)
edge_index = torch.tensor([[0, 1]], dtype=torch.long).to(device)  # Assuming only one edge between latitude and longitude

def train_model(model, optimizer, criterion, x_train, y_train, x_test, y_test, edge_index, epochs=100):
    model.train()
    train_losses = []
    test_losses = []
    for epoch in range(epochs):
        optimizer.zero_grad()
        out_train = model(x_train, edge_index)
        loss_train = criterion(out_train, y_train)
        loss_train.backward()
        optimizer.step()

        out_test = model(x_test, edge_index)
        loss_test = criterion(out_test, y_test)

        train_losses.append(loss_train.item())
        test_losses.append(loss_test.item())

        if epoch % 10 == 0:
            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {loss_train.item()}, Test Loss: {loss_test.item()}')

    # Return predicted output on the test set along with losses
    return train_losses, test_losses, out_test.detach().cpu().numpy()

# Train the model
train_losses, test_losses, predicted_output = train_model(model, optimizer, criterion, x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, edge_index)

# Print the losses and predicted output
print("Training Losses:", train_losses)
print("Testing Losses:", test_losses)
print("Predicted Output:\n", predicted_output)

plt.figure(figsize=(10, 5))
epochs = range(1, len(train_losses) + 1)
plt.plot(epochs, train_losses, label='Train Loss')
plt.plot(epochs, test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Mean Squared Error')
plt.title('Train and Test Losses Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

y_pred_df = pd.DataFrame(predicted_output, columns=y.columns)

# Convert y_test to a DataFrame
y_test_df = pd.DataFrame(y_test.values, columns=y.columns)

# Concatenate actual and predicted values
result_df = pd.concat([y_test_df, y_pred_df], axis=1)
result_df.columns = ['Actual ' + col for col in y_test_df.columns] + ['Predicted ' + col for col in y_pred_df.columns]

# Print the result DataFrame
for col in y_test_df.columns:

    print(result_df[['Actual '+col,'Predicted '+col]])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Define GNN Model
class GNNModel(MessagePassing):
    def __init__(self):
        super(GNNModel, self).__init__(aggr='mean')
        self.lin1 = Linear(2, 256)  # Input layer (latitude, longitude) to 256 hidden units
        self.lin2 = Linear(256, 512)  # 256 hidden units to 512 hidden units

        self.lin3 = Linear(512, y.shape[1])  # 512 hidden units to output dimension

    def forward(self, x, edge_index):
        x = F.relu(self.lin1(x))
        x = F.relu(self.lin2(x))

        x = self.lin3(x)
        return x

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GNNModel().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.MSELoss()

# Convert data to tensors and move to appropriate device
x_train_tensor = torch.tensor(X_train.values, dtype=torch.float).to(device)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).to(device)
x_test_tensor = torch.tensor(X_test.values, dtype=torch.float).to(device)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float).to(device)
edge_index = torch.tensor([[0, 1]], dtype=torch.long).to(device)  # Assuming only one edge between latitude and longitude

def train_model(model, optimizer, criterion, x_train, y_train, x_test, y_test, edge_index, epochs=100):
    model.train()
    train_losses = []
    test_losses = []
    for epoch in range(epochs):
        optimizer.zero_grad()
        out_train = model(x_train, edge_index)
        loss_train = criterion(out_train, y_train)
        loss_train.backward()
        optimizer.step()

        out_test = model(x_test, edge_index)
        loss_test = criterion(out_test, y_test)

        train_losses.append(loss_train.item())
        test_losses.append(loss_test.item())

        if epoch % 10 == 0:
            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {loss_train.item()}, Test Loss: {loss_test.item()}')

    # Return predicted output on the test set along with losses
    return train_losses, test_losses, out_test.detach().cpu().numpy()

# Train the model
train_losses, test_losses, predicted_output = train_model(model, optimizer, criterion, x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor, edge_index)

# Print the losses and predicted output
print("Training Losses:", train_losses)
print("Testing Losses:", test_losses)
print("Predicted Output:\n", predicted_output)

plt.figure(figsize=(10, 5))
epochs = range(1, len(train_losses) + 1)
plt.plot(epochs, train_losses, label='Train Loss')
plt.plot(epochs, test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Mean Squared Error')
plt.title('Train and Test Losses Over Epochs')
plt.legend()
plt.grid(True)
plt.show()



y_pred_df = pd.DataFrame(predicted_output, columns=y.columns)

# Convert y_test to a DataFrame
y_test_df = pd.DataFrame(y_test.values, columns=y.columns)

# Concatenate actual and predicted values
result_df = pd.concat([y_test_df, y_pred_df], axis=1)
result_df.columns = ['Actual ' + col for col in y_test_df.columns] + ['Predicted ' + col for col in y_pred_df.columns]

# Print the result DataFrame
for col in y_test_df.columns:

    print(result_df[['Actual '+col,'Predicted '+col]])

"""# XGBoost"""

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Step 1: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Train the XGBoost model
model = xgb.XGBRegressor(objective='reg:squarederror')  # Use squared error as the objective for regression
model.fit(X_train, y_train)

# Step 3: Make predictions on the training and testing data
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Step 4: Calculate the MSE for both training and testing predictions
train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)

# Step 5: Print the MSE values
print("Training MSE:", train_mse)
print("Testing MSE:", test_mse)

# Convert the predictions to a DataFrame
y_pred_df = pd.DataFrame(y_pred, columns=y.columns)

# Convert y_test to a DataFrame
y_test_df = pd.DataFrame(y_test.values, columns=y.columns)

# Concatenate actual and predicted values
result_df = pd.concat([y_test_df, y_pred_df], axis=1)
result_df.columns = ['Actual ' + col for col in y_test_df.columns] + ['Predicted ' + col for col in y_pred_df.columns]

# Print the result DataFrame
for col in y_test_df.columns:

    print(result_df[['Actual '+col,'Predicted '+col]])

"""# Random Forest"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Step 1: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Train the Random Forest model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Step 3: Make predictions on the training and testing data
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Step 4: Calculate the MSE for both training and testing predictions
train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)

# Step 5: Print the MSE values
print("Training MSE:", train_mse)
print("Testing MSE:", test_mse)